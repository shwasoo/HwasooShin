---
title: "Homework 5"
output:
  html_document:
    df_print: paged
---

## Problem 2

We will get the sum square total using loop and vector operations.

```{r}
set.seed(12345) #Set the seed for random generator
y<-seq(1,100,length.out=1e8) + rnorm(1e8)
sst<-0 #Initial value for Sum square total
meany<-mean(y)

system.time({
for(i in 1:length(y)){
  sst<-sst+(y[i]-meany)^2 #Culmulate every sum square
}}
)
print(sst) #The value we got from loop

system.time(crossprod(y-mean(y),y-mean(y)))

```
Through these steps we can check that vector operation is far more time-efficient than loop operations.

## Problem 3

```{r}
set.seed(1256) #Set the seed for random generator
theta<-as.matrix(c(1,2),nrow=2) #Initial values for parameter
X<-cbind(1,rep(1:10,10)) #Matrix of X
h<-X%*%theta+rnorm(100,0,0.2) #Matrix of Y
tol=0.00001 #Tolerance.
alpha=0.02 #alpha, which will be the step size
i=0 #Initial value for the loop
thetap<-theta #Previous value of theta
theta[1,1]<-theta[1,1]-alpha/100*sum(X%*%theta-h) #Change of first parameter
theta[2,1]<-theta[2,1]-alpha/100*sum((X%*%theta-h)*X[,2]) #Change of second parameter

while((abs(theta[1,1]-thetap[1,1])>tol)&(abs(theta[2,1]-thetap[2,1])>tol)){
thetap<-theta
i=i+1 #Number of loops
theta[1,1]<-theta[1,1]-alpha*mean(X%*%theta-h) 
theta[2,1]<-theta[2,1]-alpha/mean((X%*%theta-h)*X[,2])
if(i==500){
  print('Error: Too many loops') #Loop break, just in case.
  break
}
}
cat(i,'times looped\n') #Give a message of loops
theta #Value of parameters
```

It shows that the program looped for 308 times, and we can get the value $\Theta_{0}\approx6.536$ and $\Theta_{1}\approx0.992$.

## Problem 4

The given formula is used for getting the parameters of linear regression. X is the given data for independent variables, *y* is the dependent variable. The original formula of this will be $Y = X\beta+\epsilon$. When we are to get the estiamtor of $\beta$, we can simply use the formula above. When using in R, say X is your data and y is your dependent variable, then $Y=X\beta$ so that $\beta = (X'X)^{-1}X'Y$. Therefore, when the Given data is X and Y, you can get the parameters by $solve(t(X) \%*\% X) \%*\% t(X)\%*\%Y$.

## Problem 5

```{r}
set.seed(12456)

G<-matrix(sample(c(0,0.5,1),size=16000,replace=T),ncol=10)
R<-cor(G)
C<-kronecker(R,diag(1600))
id<-sample(1:16000,size=932,replace=F)
q<-sample(c(0,0.5,1),size=15068,replace=T)
A<-C[id,-id]
B<-C[-id,-id]
p<-runif(932,0,1)
r<-runif(15068,0,1)
C<-NULL

object.size(A) #Size of data A
object.size(B) #Size of data B

qm<-matrix(q) #Make the vector into matrix
rm<-matrix(r) #We should make vector into matrix, since we are doing matrix operations
pm<-matrix(p)
print(system.time({
  y<-pm+A%*%solve(B)%*%(qm-rm)
})) #Wrap system.time with print to get the time that took to run the code
#Total time that was used to generate y
```

From these steps, we can get the y value, size of data, and process time. In order to get the results we should first define each vector and use them to do matrix. operations. After defining the vectors, we should change them into matrix to complete computation. We can use the matrix operators (%*%) in R, but to speed up processing time, we can use some other data type called 'data.table'.

```{r}
library(data.table) #A package to use 'data.table'

G<-matrix(sample(c(0,0.5,1),size=16000,replace=T),ncol=10)
R<-cor(G)
C<-kronecker(R,diag(1600))
id<-sample(1:16000,size=932,replace=F)
q<-sample(c(0,0.5,1),size=15068,replace=T)
A<-C[id,-id]
B<-C[-id,-id]
p<-runif(932,0,1)
r<-runif(15068,0,1)
C<-NULL

Ad<-data.table(A)
tAd<-data.table(t(Ad))
Bd<-data.table(B)
Binvd<-solve(Bd) 
pd<-data.table(p) 
qm<-matrix(q) #Make the vector into matrix
rm<-matrix(r) #We should make vector into matrix, since we are doing matrix operations
pm<-matrix(p)

print(system.time({
  One<-tAd[,lapply(.SD,function(x){rbind(x)%*%Binvd})]
  Two<-One[,lapply(.SD,function(x){rbind(x)%*%(qm-rm)})]
  Two<-data.table(t(Two))
  Three<-pd-Two
}))

```

We can see that the time we uesd to do the matrix operations as reduced.